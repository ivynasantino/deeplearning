{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gradient_checking.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZOyZz0Whjht21oQrpT3W0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivynasantino/deeplearning/blob/master/exercises/gradient_checking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nehOykPJGE05",
        "colab_type": "text"
      },
      "source": [
        "Welcome to this week's third programming assignment! You will be implementing gradient checking to make sure that your backpropagation implementation is correct. By completing this assignment you will:\n",
        "\n",
        "- Implement gradient checking from scratch.\n",
        "\n",
        "- Understand how to use the difference formula to check your backpropagation implementation.\n",
        "\n",
        "- Recognize that your backpropagation algorithm should give you similar results as the ones you got by computing the difference formula.\n",
        "\n",
        "- Learn how to identify which parameter's gradient was computed incorrectly.\n",
        "\n",
        "Take your time to complete this assignment, and make sure you get the expected outputs when working through the different exercises. In some code blocks, you will find a \"#GRADED FUNCTION: functionName\" comment. Please do not modify it. After you are done, submit your work and check your results. You need to score 80% to pass. Good luck :) !"
      ]
    }
  ]
}