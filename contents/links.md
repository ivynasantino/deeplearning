## Useful links

### Summary

- [Deep learning - intro](#deep learning)
- [Neural network](#neural network)
- [Logistic regression](#logistic regression)
- [Loss function](#loss function)
- [Gradient descent](#gradient descent)
- [Activation function](#activation function)
- [Backpropagation](#backpropagation)
- [Hyperparameters](#hyperparameters)
- [Bias vs Variance](#bias vs variance)
- [Regularization](#regularization)
- [Dropout](#dropout)

#### Neural network
- [Build your first neural network - Keras](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/)
- [Medium: How to build your own neural network from scratch in Python](https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6)

- [Medium: Simple neural networks in Python](https://towardsdatascience.com/inroduction-to-neural-networks-in-python-7e0b422e6c24)

- [Medium: ANN Pima India Diabetes](https://medium.com/@randerson112358/build-your-own-artificial-neural-network-using-python-f37d16be06bf)

#### Deep learning
- [Introdution Deep learning](https://www.sas.com/pt_br/insights/analytics/deep-learning.html)

#### Logistic regression
- [Medium: Logistic regression detailed overview](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc)

- [Interpretatable ml - logistic regression](https://christophm.github.io/interpretable-ml-book/logistic.html)

#### Loss function
- [Intro loss functions](https://algorithmia.com/blog/introduction-to-loss-functions)

- [Common loss functions](https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23)

- [how to choose loss functions](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/)

#### Gradient descent

#### Activation function

#### Backpropagation

#### Hyperparameters

#### Bias vs Variance

#### Regularization

#### Dropout


